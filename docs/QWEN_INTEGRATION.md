# Qwen 2.5 32B Instruct Integration Guide

## Overview
We've successfully integrated the **Qwen 2.5 32B Instruct** model from Hugging Face into your AI Playground. This is a state-of-the-art open-source Large Language Model with 32 billion parameters, optimized for instruction following and reasoning tasks.

## Features
- **Multi-turn conversations** with context retention
- **Code generation** capabilities
- **Creative writing** and content generation
- **Question answering** with reasoning
- **Multilingual support** (100+ languages)
- **Streaming responses** for real-time interaction

## Setup Instructions

### 1. Get Hugging Face API Key
1. Go to [Hugging Face](https://huggingface.co)
2. Sign up or log in to your account
3. Navigate to Settings â†’ Access Tokens
4. Create a new token with `read` permissions
5. Copy the token

### 2. Configure Environment
Add your Hugging Face API key to your `.env.local` file:
```env
NEXT_PUBLIC_HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxx
```

### 3. Usage
1. Navigate to the AI Playground at `/ai`
2. In the Chat tab, click the settings icon
3. Select "Qwen 2.5 32B Instruct ðŸ†•" from the model dropdown
4. Start chatting!

## API Endpoints

### Chat Endpoint
```typescript
POST /api/ai/chat/qwen
{
  "messages": [
    { "role": "system", "content": "You are a helpful assistant." },
    { "role": "user", "content": "Your question here" }
  ],
  "settings": {
    "maxTokens": 2048,
    "temperature": 0.7,
    "topP": 0.95,
    "stream": false
  }
}
```

### Test Connection
```typescript
GET /api/ai/chat/qwen
// Returns model info and connection status
```

## Model Capabilities

### Strengths
- **Reasoning**: Excellent at logical reasoning and problem-solving
- **Code**: Strong code generation in multiple programming languages
- **Context**: Handles long contexts up to 32K tokens
- **Multilingual**: Supports 100+ languages including Chinese, English, Spanish, etc.
- **Instruction Following**: Highly accurate at following complex instructions

### Use Cases
1. **Technical Support**: Answer technical questions and debug code
2. **Content Creation**: Generate articles, stories, and documentation
3. **Data Analysis**: Interpret data and provide insights
4. **Translation**: Translate between multiple languages
5. **Education**: Explain complex concepts and tutor students

## Performance Considerations

### Response Times
- **First token**: ~500-1000ms
- **Generation speed**: ~20-30 tokens/second
- **Total response**: 2-5 seconds for typical queries

### Rate Limits
- **Free tier**: 1000 requests/month
- **Pro tier**: 10,000 requests/month
- **Enterprise**: Unlimited with dedicated endpoints

### Best Practices
1. **Use streaming** for better UX on longer responses
2. **Adjust temperature** (0.1-0.3 for factual, 0.7-0.9 for creative)
3. **Set appropriate max tokens** to control response length
4. **Include system prompts** for consistent behavior

## Cost Comparison

| Model | Provider | Cost/1M tokens | Quality |
|-------|----------|----------------|---------|
| Qwen 2.5 32B | Hugging Face | Free (limited) | Excellent |
| GPT-4 | OpenAI | $30-60 | Excellent |
| Claude 3 | Anthropic | $15-75 | Excellent |
| GPT-3.5 | OpenAI | $0.50-2 | Good |

## Troubleshooting

### Common Issues

1. **"Model is loading"**: The model needs 1-2 minutes to warm up on first request
2. **Rate limit exceeded**: Upgrade to Pro tier or implement caching
3. **Timeout errors**: Increase timeout settings or use streaming
4. **Invalid API key**: Check your Hugging Face token permissions

### Debug Commands
```bash
# Test API connection
curl http://localhost:3009/api/ai/chat/qwen

# Test chat functionality
curl -X POST http://localhost:3009/api/ai/chat/qwen \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hello"}]}'
```

## Advanced Configuration

### Custom Model Parameters
Edit `/src/lib/ai/qwen-model.ts` to customize:
- Default temperature
- Max tokens
- Top-p sampling
- Repetition penalty

### Using Different Qwen Models
You can also use other Qwen models:
- `Qwen/Qwen2.5-7B-Instruct` (smaller, faster)
- `Qwen/Qwen2.5-72B-Instruct` (larger, more capable)
- `Qwen/Qwen2.5-Coder-32B-Instruct` (optimized for code)

## Security Notes
- API key is stored as `NEXT_PUBLIC_*` for client-side access
- For production, consider using server-side only access
- Implement rate limiting per user
- Add request validation and sanitization

## Support & Resources
- [Qwen Model Card](https://huggingface.co/Qwen/Qwen2.5-32B-Instruct)
- [Hugging Face Inference API Docs](https://huggingface.co/docs/api-inference)
- [Model Performance Benchmarks](https://qwenlm.github.io/blog/qwen2.5/)
- [Community Discord](https://discord.gg/qwen)

## Future Enhancements
- [ ] Add conversation history persistence
- [ ] Implement model fine-tuning interface
- [ ] Add support for function calling
- [ ] Create model A/B testing framework
- [ ] Add response caching for common queries
- [ ] Implement user preference learning